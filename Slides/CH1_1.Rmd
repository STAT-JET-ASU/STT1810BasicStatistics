---
title: "Section 1.1 Introduction<br>to Chance Models"
subtitle: "Introduction to Statistical Investigations, 2^nd^ Edition"
author: "Jill E. Thomley | **STT 1810 BASIC STATISTICS** | Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```


## Before We Beginâ€¦

These slides are intended to accompany Section 1.1 Intro to Chance Models in [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html). 

*This content does not replace reading the textbook section.* It is for class presentation and/or reference.

See also:

* Glossary of ISI Textbook Vocabulary on AsULearn
* Example 1.1 Can Dolphins Communicate? (slides TBA)


## Recall: Spiral Approach & Four Pillars

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* **&#187; We will address *strength* of evidence (significance) in Chapter 1. &#171;**

* We will discuss *breadth* of results (**generalization**) in Chapter 2.

* We will learn about *size* for an effect (**estimation**) in Chapter 3.

* Chapter 4 will introduce the idea of **causation**, the last of the four pillars. 

:::

::::


## Learning Goals for Chapter 1

* Use the chance model to determine whether an observed statistic is unlikely to occur. [Section 1.1]
* Calculate and interpret a *p*-value, and state the strength of evidence it provides against the null hypothesis. [Section 1.2]
* Calculate a standardized statistic for a single proportion and evaluate the strength of evidence it provides against a null hypothesis. [Section 1.3]
* Describe how the distance of the observed statistic from the parameter value specified by the null hypothesis, sample size, and one- vs. two-sided tests affect the strength of evidence against the null hypothesis. [Section 1.4]

We will *not* be covering Section 1.5, which discusses the theory-based approach to inference for a single proportion.


## Learning Goals for Section 1.1

* Recognize the difference between parameters and statistics.
* Describe how to use coin tossing to simulate outcomes from a chance model of a random choice between two events.
* Use the [ISI One Proportion applet](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) to carry out a coin tossing simulation.
* Identify whether or not the results of a study are statistically significant and whether or not a chance model is a plausible explanation for the data.
* Implement the 3S strategy: find a statistic, simulate results from a chance model, and determine strength of evidence.
* Differentiate between saying a chance model is plausible and a chance model is the correct explanation for observed data (i.e., whether or not we have "proven" a result).


## What is a Chance Model?

<h3 style="text-align: center;">Generally speaking, what is a *model* ?</h3>

<h3 style="text-align: center;">What about a *mathematical model* ?</h3>

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/molecularmodel.jpg", dpi = 110)
```

<h3 style="text-align: center;">Building on these two ideas, what is a *chance model* ?</h3>


## Textbook Definitions

(mathematical) **model**

* A mathematical or probabilistic conceptualization meant to closely match reality, but always making assumptions about that reality, which may or may not be true.

**chance model**

* A real or computerized process to generate data according to a well-understood set of conditions." --- *to model some real-life random process we are interested in studying*

<hr> 

In the real world we are almost always dealing with incomplete data (i.e., *samples*). Therefore, in statistics, we logically compare outcomes we observe in the real world to hypothetical chance models. This is the foundation of *statistical inference*.


## Section 1.1 New Vocabulary

* chance model
* parameter
* sample
* sample size
* simulate
* statistic
* statistically significant
* strength of evidence
* 3S strategy

## 

**chance model:** a physical / tactile or computerized process to generate random data according to a "well-understood" set of conditions (i.e., the properties of the real-life random process we are studying; we may need to make some assumptions)

***Example:*** For the ESP test we did, one condition was using an open deck (*sampling with replacement*) so that the probability of random guessing on each trial would stay the same. We also assumed there was no other way for someone to know which card was drawn (e.g., marked cards, cheating).

***Example:*** For the Monty Hall game, we assumed that the prize was equally likely to be placed behind any of the three doors. In our extended version, a condition was that we also opened all of the unchosen doors *except one* after the initial guess.

We often use cards, coins, dice, and spinners to help us model random processes, as well as computer programs/applets.


## 

**parameter:** a long-run numerical property of a random process

***Example:*** Across a large number of instances of the Monty Hall game, what is the probability a wins player if they switch? This is the scenario we investigated with our 1000+ simulations of the game using  applets. The long-run probability is a parameter.

***Example:*** For the ESP example, it is be someone's innate chance of identifying a card (1/5 if they do not have ESP, more than 1/5 if they do have ESP.) This would be reflected in their long-term performance on the test---many more trials than 25. Remember, the web site suggested that 50+ trials were necessary for you to get "a reliable indication of your performance".


**sample:** the set of observational units on which we collect data

***Examples:*** One round of the Monty Hall game is a unit; one card guessed in our Zener card ESP test is a unit.


## 

**sample size:** the number of observational units $n$ in a sample

***Examples:*** We initially did $n$ = 15 trials of the Monty Hall game in our investigations. For our ESP test, we attempted $n$ = 25 cards.

**statistic:** a numerical value that summarizes results in a sample (i.e., results in the set of *observed data*)

***Examples:*** For Monty Hall, we recorded a win (car) or loss (goat) for each individual trial, then counted the total number of wins and calculated the fraction of wins. For the ESP test, we counted the number of cards we correctly guessed.

**statistically significant:** unlikely to occur just by random chance 

In other words, the observed result *could* be solely a product of random chance, but it's not *likely* to be just random chance (i.e., random chance alone is not a *plausible* explanation).


## The 3S Strategy

This is a method for assessing the evidence provided by data.

**statistic:** Compute a statistic from your observed sample data. 

**simulate:** Identify a possible "by-chance-alone" explanation for the data.   Repeatedly simulate values of the statistic that *could* happen when the chance model is true (*purely random results*).  

**strength of evidence:** Compare your observed statistic to the simulated values. As you do this, consider whether the statistic from the sample data is *unlikely* when the chance model is true. 

<hr>

If we decide the observed statistic is unlikely to occur by chance alone, we can logically conclude that the observed data provide us strong evidence against the *plausibility* (i.e., the *believability* or the *credibility*) of the chance model --- but *not* "proof". 


## Connecting 3S to the Spiral Approach

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* The first S (*compute a statistic from observed sample data*) occurs at Step 3/4 of the process. 

* The second S (*devise and perform a simulation to model "by chance alone" outcomes*) and the third S (*compare your observed statistic to the distribution of simulated values*) are the foundation of Step 4. 

* "strength of evidence" &rarr; part of logic of inference

:::

::::


## [ISI One Proportion Applet](https://www.isi-stats.com/isi2nd/ISIapplets2021.html)

:::::: {style="display: flex;"}

::: {}

* Probability of heads = value of parameter

* Number of tosses = $n$ (sample size)

* Number of repetitions = 1000 (or more simulations)

* Number of heads = from sample data

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/OneProportionApplet.png", dpi = 120)
```

:::

::::


## Modeling 10 Flips of a Fair Coin

:::::: {style="display: flex;"}

::: {}

* Probability of heads is 0.5 for a fair coin

* One repetition is 10 flips

* The plot shows us the results from our 1000 reps; it is the distribution of the randomly varying *counts* or *proportions* of heads

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/OneProportionAppletEx.png", dpi = 120)
```

:::

::::
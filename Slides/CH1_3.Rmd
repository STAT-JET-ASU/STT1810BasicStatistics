---
title: "STT1810 --- Section 1.3<br>Strength of Evidence #2"
subtitle: "Introduction to Statistical Investigations, 2^nd^ Edition"
author: "Author: Jill E. Thomley // Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```


## Recall: Spiral Approach & Four Pillars

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* We will address *strength* of evidence (significance) in Chapter 1.

* We will discuss *breadth* of results (generalization) in Chapter 2.

* We will learn about *size* of an effect (estimation) in Chapter 3.

* Chapter 4 will introduce the idea of *causation*, the last of the four pillars. 

:::

::::


## Learning Goals for Chapter 1

* Use the chance model to determine whether an observed statistic is unlikely to occur. [Section 1.1]
* Calculate and interpret a p-value, and state the strength of evidence it provides against the null hypothesis. [Section 1.2]
* Calculate a standardized statistic for a single proportion and evaluate the strength of evidence it provides against a null hypothesis. [Section 1.3]
* Describe how the distance of the observed statistic from the parameter value specified by the null hypothesis, sample size, and one- vs. two-sided tests affect the strength of evidence against the null hypothesis. [Section 1.4]

We will *not* be covering Section 1.5, which discusses the theory-based approach to inference for a single proportion.


## Learning Goals for Section 1.3

* Find a standardized statistic from the observed proportion of “successes” in the data, the hypothesized mean of the null distribution (i.e., *the value of the parameter that is specified in Ho*), and standard deviation (SD) of the null distribution as produced by the [ISI One Proportion Applet](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) (i.e., simulation).
* Interpret a standardized statistic.
* State a conclusion about the alternative hypothesis (and null hypothesis Ho) based on the magnitude of the standardized statistic.
* Recognize that standardizing the statistic is an alternative measure of strength of evidence.


## Section 1.3 New Vocabulary

**test of significance:** 

This is the formal process we usually follow for any assessment of strength of evidence.

(1) Make a claim about the parameter of interest (Ho and Ha) 
(2) Gather and explore data relevant to the claim
(3) Calculate an observed statistic from the data
(4) Simulate a null distribution (assuming that Ho is true)
(5) Measure the strength of evidence that the observed statistic provides against Ho (using the null distribution as a "ruler")
(6) Draw a conclusion about the null hypothesis 

*Recall that steps 3, 4, and 5 are the components of the 3S process!*


## 

**standardize / standardized statistic:** To standardize a statistic, compute the distance of the observed statistic from the mean (hypothesized) of the null distribution, then divide by the SD of the null distribution.

$$\text{std. statistic} = \frac{\text{statistic} - \text{mean of null distribution}}{\text{SD of null distribution}}$$

Mathematically, this is similar to transforming °F to °C --- it's a new scale that doesn't change the *meaning* of the data. 

When performing this rescaling, the *units of measurement* cancel out, which is why it's *standardized* and applicable across a broad range of possible problems.

The value tells us how many SDs the observed statistic is above or below the hypothesized mean.


## Flashback: [ESP Test](https://stat-jet-asu.github.io/Slides/STT1810/ESPZenerCards.html)

***Example:*** We can [simulate](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) a null distribution for our Zener card ESP test, assuming everyone is guessing ($\pi = 0.20, n = 25$). 

$$H_o: \pi = 0.20$$

$$H_a: \pi > 0.20$$

The mean of the null distribution is 0.20. The standard deviation is 0.08. Suppose that I identify 8 out of 25 cards correctly.

$$\text{standardized statistic} = \frac{8/25 - 0.20}{0.08} = 1.5$$

My result is one and a half standard deviations above the mean (i.e., *one and a half times the average deviation from the mean*).


## 

I used 10,000 repetitions to get a more reliable SD estimation.

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/OneProportionAppletZener.png", dpi = 150)
```


## Quantifying Strength of Evidence

As with *p*-values, there are some guidelines for interpretation. A large standardized score generally indicates the observed value is in one of the *tails* of the null distribution rather than near the center (it is farther away from being a "typical" value).

| Magnitude                | Guideline for Inference                       |
|--------------------------|-----------------------------------------------|
| between -1.5 and +1.5    | not much evidence against Ho; Ho is plausible |
| below -1.5 or above +1.5 | moderate evidence against Ho                  |
| below -2.0 or above +2.0 | strong evidence against Ho                    |
| below -3.0 or above +3.0 | very strong evidence against Ho               |


## Mound-Shaped Example

Notice that the center of the distribution is 0. Values *below* the mean will have a negative standardized score.

```{r, echo = FALSE, fig.align="center", fig.cap="standardized statistics on a bell-shaped distribution." }
knitr::include_graphics("images/stdstatbellcurve.png", dpi = 110)
```

The farther from zero the standardized statistic is, the stronger the evidence against the null hypothesis. Like a *p*-value, we can directly compare standardized values across datasets.



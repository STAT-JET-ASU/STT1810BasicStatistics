---
title: "Section 3.1<br>Confidence Intervals"
subtitle: "Introduction to Statistical Investigations, 2^nd^ Edition"
author: "Jill E. Thomley | **STT 1810 BASIC STATISTICS** | Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```

## Before We Begin…

These slides are intended to accompany Section 3.1 Estimation: How Large Is the Effect? in [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html). 

*This content does not replace reading the textbook section.* It is for class presentation and/or reference.

See also:

* Glossary of ISI Textbook Vocabulary on AsULearn
* Example 3.1 Can Dogs Sniff Out Cancer (slides TBA)


## Recall: The Spiral Process & Four Pillars

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* We addressed *strength* of evidence (**significance**) in Chapter 1. ✔ ***Good job!***

* We will discuss *breadth* of results (**generalization**) in Chapter 2. ✔ ***Good job!***

* &#187; We will learn about *size* for an effect (**estimation**) in Chapter 3. &#171;

* Chapter 4 will introduce the idea of **causation**, the last of the four pillars. 

:::

::::


## Learning Goals for Chapter 3

Chapter 3 focuses on ***estimation***, which is one of the four pillars of inference introduced in Section P.1. Often, we use estimation to indicate how large an effect is, not as a single number, but as an ***interval*** of statistically likely or plausible values.

<hr>

In this chapter, you will learn to: 

* Construct and interpret a confidence interval for a single population proportion using the range of plausible values technique. [Section 3.1]
* Construct and interpret a confidence interval for a single population proportion using the 2SD method. [Section 3.2]
* Identify how factors (confidence level, sample size, SD) affect the width of the confidence interval. [Section 3.4]


## Learning Goals for Section 3.1

In Chapter 3, you will learn two different ways to find confidence intervals, based on methods from Chapters 1 and 2. The first is an interval of plausible values --- those values of the parameter that are *not* rejected in a two-sided test of significance. 

<hr>

* Complete multiple two-sided tests of significance, using the same value for the sample proportion but changing the value under the null hypothesis, and obtain an interval of plausible values for the population parameter.
* Interpret an interval of plausible values as estimating the population parameter and as a confidence interval.
* Based on the results of a test of significance, infer whether or not a value is in the confidence interval and vice versa.


## Section 3.1 New Vocabulary

* confidence interval
* confidence level
* estimate / estimation
* plausible value(s)
* significance level

This chapter builds on Chapters 1 and 2, so you also will want to be sure that you have solidified vocabulary from those chapters, including (but not limited to) terms such as...

* null hypothesis and parameter
* sampling distribution
* test of significance


## 

**confidence interval:** An inference tool used to estimate the value of a parameter such as $\pi$, with an associated measure of uncertainty due to the randomness in the sampling method.

**confidence level:** A statement of reliability in the confidence interval method.

**estimation:** In the context of confidence intervals, describes how large an effect is in terms of a range of values for the parameter of interest.

**plausible value:** A parameter value that is tested under the null hypothesis where, based on the observed data, we do not find strong evidence against the null (Ho is not rejected).

**significance level:** A value used as a criterion for deciding how small a *p*-value in a test of significance needs to be to provide convincing evidence against the null hypothesis.


## Method of Plausible Values

Test many different values of $\pi$ as the null hypothesis.

$$H_0: \pi = \text{value being tested}$$

$$H_a: \pi \ne \text{value being tested}$$

Calculate a two-sided *p*-value using the observed data.

Reject Ho *or* fail to reject Ho using the *p*-value and the chosen level of significance (most commonly $\alpha = 0.05$).

If you fail to reject Ho, then the tested value of $\pi$ is a *plausible value* and therefore it belongs in the confidence interval.

The interval boundaries are the smallest and largest plausible values, often written as (*lower boundary*, *upper boundary*).


## What Does 95% Confidence Mean?

Let us start with what it does *not* mean. It does not mean that there is a 95% chance that the actual value of the parameter is in the 95% confidence interval. *Why not?*

The parameter value is fixed and the interval is random. If you chose a different sample, you’d get a different interval, but the parameter value would still be the same. 

What we mean is that 95% of all samples give an interval that covers the true value. The 95% is the “coverage probability” or “capture rate" of the **method** we are using. This is like Section 2.1, where we said that "unbiased" is a property of a sampling method, not an individual sample.

In statistics, we validate our **methods**, because we cannot know for sure how our sample relates to a population.


## Another Analogy

Picture a game of horseshoes. The parameter is the iron stake in the ground, which does not move. Each toss of a horseshoe is an interval. We might barely catch the stake, or we might get a solid ringer. Both count! Our method is a like really good player who can get a horseshoe around the stake 95% of the time.

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/garfieldCI.jpg", dpi = 100)
```

We could have a 100% confidence interval for a $\pi$ if we said the value was between 0 and 1 --- but that wouldn't be particularly useful in most contexts, would it?


## Flashback: Harley the Wonder Doggo

In Section 1.1, we explored the question "Can Dogs Understand Human Cues?" In a particular set of 10 trials, Harley was able to pick the correct cup 9 out of 10 times. We decided that this was statistically significant and $H_0: \pi = 0.50$ was implausible. 

So, if Harley is not purely guessing when the experimenter bows toward the cup, what is his true long-run probability $\pi$ of picking the correct cup? After the test we just know $H_a: \pi > 0.5$.

Given that $\hat{p}$ is 0.90, that might be a good estimate (i.e., *informed guess*) for the value of $\pi$. We call that a *point estimate*.

However, this is sample data, and we all know that it has some random variability. Maybe $\pi$ is a little bit different than 0.90, like 0.89. Could it be more different, like 0.80? Or even 0.70? 


##

We can systematically test different values for $\pi$ on either side of $\pi = 0.90$, until we get to values that are implausible. We will use the same kind of simulation we did for the original test.

| $\pi$ tested in Ho |  0.56 |  0.57 |  ...  |  0.85 |  0.90 |  0.95 |  0.99 |  1.00 |
|--------------------|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|:-----:|
| two-sided *p*-value| 0.049 | 0.052 |  ...  | 1.000 | 1.000 | 0.404 | 0.096 | NA    |
| reject Ho?         | Yes   | No    |  ...  | No    | No    | No    | No    | NA    |
| plausible $\pi$?   | **NO**| Yes   |  ...  | Yes   | Yes   | Yes   | Yes   | **NO**|

We know 1 is not possible; that would mean Harley is *guaranteed* to always choose the correct cup. Data shows that is false.

We are 95% confident that $\pi$ is between 0.57 and 0.99. We need more data if we want a narrower interval of plausible values.


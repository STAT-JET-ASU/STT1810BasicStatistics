---
title: "STT1810 --- Section 6.1<br>Comparing Two Groups"
subtitle: "Introduction to Statistical Investigations, 2^nd^ Edition"
author: "Author: Jill E. Thomley // Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```

## Before We Beginâ€¦

These slides are intended to accompany Section 6.1 Comparing Two Groups: Quantitative Response in [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html). 

*This content does not replace reading the textbook section.* It is for class presentation and reference.

See Also:

* [Section 2.1 Exploring Data](https://stat-jet-asu.github.io/STT1810BasicStatistics/Slides/CH2_1.html)
* [Example 2.1 Oh, Say Can You Sing?](https://stat-jet-asu.github.io/STT1810BasicStatistics/Slides/Example2_1.html)
* [Example 6.1 Geyser Eruptions](https://stat-jet-asu.github.io/STT1810BasicStatistics/Slides/Example6_1.html)
* [Section 6.2 Compare Two Means: Simulation-Based Approach](https://stat-jet-asu.github.io/STT1810BasicStatistics/Slides/CH6_2.html)


## Recall: The Six-Step Spiral Process

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* In Chapters 1 through 4, our research questions usually involved a single proportion parameter $\pi$.

* In Chapter 5 we explored differences in proportions for two groups ($\pi_1 - \pi_2$).

* In Chapter 6, we will apply what we learned to assess *quantitative* variables.

* We will compare *means* of two groups ($\mu_1 - \mu_2$).


:::

::::


## Learning Goals for Chapter 6

Chapter 6 extends what we learned about statistical significance in previous chapters to compare two groups with parameters $\mu_1$ and $\mu_2$, where $\mu$ is the population *mean*. A sample mean will be designated with $\bar{x}$. We typically will have a null of $H_0: \mu_1 = \mu_2$ or $H_0: \mu_1 - \mu_2 = 0$ (i.e., *no difference*). 

We can also estimate the size of difference between $\mu_1$ and $\mu_2$.

<hr>

In this chapter, you will learn to: 

* Compare two sample means numerically and graphically. [Section 6.1]
* Carry out a simulation-based analysis to investigate the difference between two population means. [Section 6.2]


## Learning Goals for Section 6.1

* Calculate or estimate the mean, median, quartiles, five number summary, and interquartile range from a dataset and understand what these are measuring.

* When comparing two quantitative distributions, identify which has the larger mean, median, standard deviation, and inter-quartile range.

* Identify whether there is likely an association between a binary categorical variable and a quantitative response variable.


## Section 6.1 New Vocabulary

* five-number summary
   * minimum
   * lower quartile
   * median
   * upper quartile
   * maximum
* interquartile range
* boxplot

We also will revisit several vocab terms from the Preliminaries and introduce a guideline for identifying data points that might be considered outliers in a quantitative *distribution*.


## Descriptive Statistics

**minimum:** the smallest value observed for the variable

**lower quartile:** the value that divides the variable so that 25% of the data values lie below (and 75% lie above); also known as the 25th percentile

**median:** a measure of center where 50% of the data values lie below and 50% lie above, when data values are arranged from minimum to maximum; also called the 50th percentile

**upper quartile:** the value that divides the variable so that 75% of the data values lie below (and 25% lie above); also known as the 75th percentile

**maximum:** the largest value observed for the variable


## 

**five-number summary:** a set of five data summaries composed of minimum, lower quartile, median, upper quartile, maximum. These five values break the data into four parts, with each part containing 25% of the data points.

**interquartile range:** a measure of spread for the middle 50% of the data values, which is found by taking the distance between the quartiles; IQR = upper quartile --- lower quartile

**boxplot:** a visual display of the five-number summary, which can help us identify symmetry and outliers

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/boxplotkernler01.gif", dpi = 175)
```
<p style = "text-align: center; font-size: 10px;"><br>Image Source: [Prof. Dan Kernler for Mth120 Statistics I at Elgin Community College](https://faculty.elgin.edu/dkernler/statistics/ch03/3-5.html)</p>


## Recall: Exploring Data (Section P.2)

Quantitative data are described by how / where they occur on the number line. Distribution behavior includes:

**shape:** the overall pattern and "clumping" of the data when we graph it (e.g., using a dotplot or histogram; *now also a boxplot*)

**center:** a middle or typical value of a quantitative variable; the "center of mass" for the distribution (e.g., mean *or median*)

**variability:** once we have identified the center, how spread out are the data---are most within a certain range (e.g., SD *or IQR*)?

**unusual observations / features:** points that deviate markedly from the overall pattern of the other data values (i.e., *now we can use boxplots to detect outliers*); also other unusual features such as multiple modes (note: boxplots are *not* good for this)


## Anatomy of a Boxplot

Boxplots may be drawn horizontally or vertically (*left* = *lower*).

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/boxplotanatomy.png", dpi = 100)
```

* lower outlier = data value < $\text{lower quartile} - 1.5 * IQR$
* upper outlier = data value > $\text{upper quartile} + 1.5 * IQR$


## Boxplots and Skewness

**Symmetric:** The lower quartile is (roughly) equally far from the median as the upper quartile; he left whisker is (roughly) equal in length to the right whisker. Overall, does not demonstrate a consistent pattern of skewness (*see next slide*).

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/boxplotkernler02.gif")
```

The smaller the sample size, the less useful a boxplot might be for discussing shape. In any case, it should be used along with another plot like a histogram.


##

**Left Skewed:** The lower quartile is further from the median than the upper quartile; left whisker is longer than right whisker.

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/boxplotkernler03.gif")
```

**Right Skewed:** It is the reverse or "mirror image" of left skewed.

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/boxplotkernler04.gif")
```
<p style = "text-align: center; font-size: 10px;"><br>Image Source: [Prof. Dan Kernler for Mth120 Statistics I at Elgin Community College](https://faculty.elgin.edu/dkernler/statistics/ch03/3-5.html)</p>


## Which Measures Do We Use?

Why do we need more than one measure to quantify / describe center and variability?

Skewness and outliers, especially in extreme cases, impact some measures more strongly than others.

* Median is a resistant measure of center, whereas the mean is more sensitive to extreme values and skewness.

* IQR is a resistant measure of variability, whereas the standard deviation is sensitive to extreme values and skewness.

Our preference is usually to use mean and standard deviation, but for strongly skewed data or data with large outliers, we may choose median and IQR instead.


## Impact of Skewness / Outliers

The greater the skew, the more different the mean and median will tend to be for a given distribution.

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("images/meanmedianmode.png", dpi = 210)
```
<p style = "text-align: center; font-size: 10px;"><br>Image Source: [Author Diva Jain on Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Relationship_between_mean_and_median_under_different_skewness.png)</p>

<br>

Outliers tend to pull the mean in their direction---large outliers pull the mean up, small outliers pull the mean down.


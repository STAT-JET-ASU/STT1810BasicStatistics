---
title: "Section 1.2 Measuring<br>the Strength of Evidence"
subtitle: "*Introduction to Statistical Investigations, 2^nd^ Edition*"
author: "Jill E. Thomley | **STT 1810 BASIC STATISTICS** | Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: ../images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```


## Before We Begin…

These slides were created to accompany the text [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html) --- Section 1.2 Measuring the Strength of Evidence. 

*This content does not replace reading the relevant textbook section.* It is for class presentation, review, and reference.

See [AsULearn](https://asulearn.appstate.edu/) for additional readings, videos, and assignments.

You can print these slides to a pdf for offline use using the print function in your browser.


## Recall: Spiral Approach & Four Pillars

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* **We will address strength of evidence (*significance*) in Chapter 1.**

* We will discuss breadth of results (*generalization*) in Chapter 2.

* We will learn about effect size of results (*estimation*) in Chapter 3.

* Chapter 4 will introduce the idea of *causation*, the last of the four pillars. 

:::

::::


## Learning Goals for Chapter 1

* Use the chance model to determine whether an observed statistic is unlikely to occur. [Section 1.1]
* Calculate and interpret a *p*-value, and state the strength of evidence it provides against the null hypothesis. [Section 1.2]
* Calculate a standardized statistic for a single proportion and evaluate the strength of evidence it provides against a null hypothesis. [Section 1.3]
* Describe how the distance of the observed statistic from the parameter value specified by the null hypothesis, sample size, and one- vs. two-sided tests affect the strength of evidence against the null hypothesis. [Section 1.4]

<hr>

We will not cover Section 1.5, which introduces a theory-based method of inference for a single proportion.


## Learning Goals for Section 1.2

* Use appropriate symbols for parameter and statistic.
* State the null and the alternative hypotheses in words and in terms of the symbol $\pi$, the long-run proportion.
* Explain how to conduct a simulation using a null hypothesis probability that is not 50-50.
* Use the ISI [One Proportion](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) applet to obtain the *p*-value after carrying out an appropriate simulation.
* Anticipate the null distribution's center and how it changes based on using proportion or count as the statistic.
* Interpret the $p$-value and explain why a smaller *p*-value provides stronger evidence against the null hypothesis.
* State a conclusion about the alternative hypothesis and null hypothesis based on the *p*-value.


## Section 1.2 New Vocabulary

**<mark>binary variable</mark> :** a categorical variable with only two outcomes

* we can regroup multiple outcomes into **two** categories
* one of the categories would be defined as a “success” 
* the other category would be defined as a “failure”

<hr>

***Example 1:*** The outcome of one coin flip (heads vs. tails) is a very common binary variable. In a pre-game coin flip in football, one team designates what will be a "success" by calling heads or tails before the flip occurs.

***Example 2:*** The six possible numbers that result from one roll of a six-sided die can be regrouped into odd vs. even numbers. We could then designate even numbers as the "success".


##

An essential part of our statistical ***logic of inference*** is creating a pair of opposing hypotheses that make statements regarding a parameter of the random process we are investigating.

Recall from our Section 1.1 vocabulary: *a **parameter** is a long-run numerical property of some real-world random process.*

<hr>

**<mark>null hypothesis ($H_0$)</mark> :** "by chance alone" or "there is no effect" explanation, which can be modeled by random simulation

**<mark>null distribution</mark> :** a distribution of simulated statistics that are a representation of what *could have* happened in the actual study if $H_0$ were true (we *assume* $H_0$ is true in the simulation)

**<mark>alternative hypothesis ($H_a$)</mark> :** "not by chance alone" or "there is an effect" explanation, typically reflects our research conjecture (it is also sometimes referred to as the *research hypothesis*)


## Statistical Symbols

We often use symbols to communicate or represent different quantities in a statistical analysis or to express our hypotheses. 

It is common to use Greek letters to represent parameters and Roman letters (our regular English alphabet) for statistics.

<mark>$\pi$</mark> : The Greek letter pi (or *p*), pronounced “pie.” This represents a parameter that is a proportion or probability (*not* 3.14159).

<mark>$\hat{p}$</mark> : The Roman letter p with a ^ above it, pronounced as "p-hat." It is the proportion of observational units in a sample that have a particular characteristic (or an *estimated probability*). For a *test of significance*, this would be the observed statistic.

<mark>$n$</mark> : sample size; the number of observational units in the sample


## Test of Significance

In the field of Statistics, a **<mark>test of significance<mark>** is a procedure for measuring the strength of evidence against our null hypothesis regarding the parameter of interest.

(1) Make a claim about the parameter of interest ($H_0$ and $H_a$)
(2) Gather and explore data
(3) Follow the **3S** strategy to 
    * calculate an observed ***Statistic*** from the data
    * ***Simulate*** a null distribution (*scenario assuming $H_0$ is true*)
    * compare the observed statistic to the null distribution to measure the ***Strength of evidence*** it provides *against* $H_0$.  
(4) Draw a conclusion about the plausibility of $H_0$


## Quantifying Strength of Evidence

Assuming $H_0$ is true, our **<mark>*p*-value</mark>** is the probability of getting a purely random value of a statistic that is at least as extreme (in the direction of $H_a$) as the observed statistic we are assessing.

| Magnitude               | Guideline for Inference                                    |
|-------------------------|------------------------------------------------------------|
| *p*-value > 0.10        | **NOT MUCH** evidence against the null hypothesis $H_0$    |
| 0.05 < *p*-value ≤ 0.10 | **MODERATE** evidence against the null hypothesis $H_0$    |
| 0.01 < *p*-value ≤ 0.05 | **STRONG** evidence against the null hypothesis  $H_0$     |
| *p*-value ≤ 0.01        | **VERY STRONG** evidence against the null hypothesis $H_0$ |


## Additional Guidelines (*p*-value &leq; 0.05)

Researchers across many of disciplines consider **<mark>*p*-value ≤ 0.05</mark>** (i.e., ≤ 5% chance) to be the threshold where we can claim that the data have ***<mark>statistical significance</mark>***, declare the chance model<br>($H_0$) to be implausible, and accept $H_a$ instead. 

A *p*-value ≤ 0.05 indicates we have *strong* or *very strong evidence* against the null hypothesis in our textbook guidelines.

In some situations you may want or need stronger evidence. For example, rejecting $H_0$ may have life or death consequences in a medical study, so the researchers might use *p*-value ≤ 0.01 (*very strong evidence*) as the threshold for significance.

<hr>

You may be wondering, why this particular probability (≤ 0.05)? What's so special about it?


## Why 0.05?

Ronald Fisher wrote *Statistical Methods for Research Workers* in 1925 and he chose 1 in 20 (5%) as his general guide, because it typically corresponds to roughly two standard deviations from the expected value. (*Though not without [controversy](https://www.scientificamerican.com/article/the-significant-problem-of-p-values/)...*)

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/fisherpvaluequote.png", dpi = 70)
```


## Connection: ISI [One Proportion](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) Applet

:::::: {style="display: flex;"}

::: {}

* Probability of heads = value of $\pi$ in $H_0$

* Number of tosses = $n$ (sample size)

* Number of repetitions = 1000 (or more simulations)

* Proportion of heads = $\hat{p}$

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/OneProportionAppletV1.png", dpi = 120)
```

:::

::::


## 

If you enter a probability value other than 0.5, the labels change, even if you go back to 0.5. Notice the more general phrasing...

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/OneProportionAppletV2.png", dpi = 135)
```


## General Rule for Statistical Significance

<p>We will declare the chance model ***implausible*** and reject $H_0$ if...</p>

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/freddiemercurypvalue.jpg", dpi = 100)
```

<p style="text-align:center; font-size: 12px;">With all due respect to the [late, great Freddie Mercury](https://youtu.be/FP808MiJUcM).</p>


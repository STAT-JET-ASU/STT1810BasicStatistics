---
title: "Section 1.3 Measuring Strength (an Alternative)"
subtitle: "*Introduction to Statistical Investigations, 2^nd^ Edition*"
author: "Jill E. Thomley | **STT 1810 BASIC STATISTICS** | Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: ../images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```


## Before We Begin…

These slides were created to accompany the text [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html) --- Section 1.3 Alternative Measure of Strength of Evidence. 

*This content does not replace reading the relevant textbook section.* It is for class presentation, review, and reference.

See [AsULearn](https://asulearn.appstate.edu/) for additional readings, videos, and assignments.

You can print these slides to a pdf for offline use using the print function in your browser.


## The Spiral Approach & The Four Pillars

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* **We will address strength of evidence (*significance*) in Chapter 1.**

* We will discuss breadth of results (*generalization*) in Chapter 2.

* We will learn about effect size of results (*estimation*) in Chapter 3.

* Chapter 4 will introduce the concept of *causation*, the last of the four pillars. 

:::

::::


## Learning Goals for Chapter 1

* Use the chance model to determine whether an observed statistic is unlikely to occur. [Section 1.1]
* Calculate and interpret a *p*-value, and state the strength of evidence it provides against the null hypothesis. [Section 1.2]
* Calculate a standardized statistic for a single proportion and evaluate the strength of evidence it provides against a null hypothesis. [Section 1.3]
* Describe how the distance of the observed statistic from the parameter value specified by the null hypothesis, sample size, and one- vs. two-sided tests affect the strength of evidence against the null hypothesis. [Section 1.4]

<hr>

We will *not* cover Section 1.5, which introduces a theory-based method of inference for a single proportion.


## Learning Goals for Section 1.3

* Find a standardized statistic from the observed proportion of “successes” in the data, the hypothesized mean of the null distribution, and the standard deviation (SD) of the null distribution as produced by the ISI [One Proportion](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) applet.
* Interpret a standardized statistic.
* State a conclusion about the alternative hypothesis (and null hypothesis Ho) based on the magnitude of the standardized statistic.
* Recognize that standardizing the statistic is an alternative measure of strength of evidence.


## Recall from Section 1.2

**<mark>test of significance (or significance test)</mark> :** the formal statistical process we use to assess of strength of evidence from data

(1) Make a claim about the parameter of interest ($H_0$ and $H_a$)
(2) Gather and explore data relevant to the parameter claim
(3) Calculate a corresponding observed statistic from the data
(4) Simulate a null distribution for the statistic (assuming that the null hypothesis is true)
(5) Measure the strength of evidence that the observed statistic provides against $H_0$ (using the null distribution as a "ruler")
(6) Use results to draw a conclusion about the plausibility of $H_0$

*Recall that steps 3, 4, and 5 are the components of the **3S process!***


## Section 1.3 New Vocabulary

**<mark>standardize / standardized statistic</mark> :** To standardize a statistic: (1) compute the distance between the observed statistic and the mean of the null distribution, then (2) divide the distance by the standard deviation of the null distribution.

<hr>

$$\text{std. statistic} = \frac{\text{statistic} - \text{mean of null distribution}}{\text{SD of null distribution}}$$
<hr>

The standardized statistic tells us how many standard deviations above or below the hypothesized mean the observed statistic is.

This kind of standardized value is often referred to as a **<mark>*z*-score</mark>**. Many traditional, theory-based significance tests use a statistic such as this. They are also useful for comparing data.


## 

Mathematically, standardizing is similar to transforming °F to °C. It's a new numerical scale for expressing the quantity, but it does not change the *meaning* of the actual data values. 

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/temprescaling.png", dpi = 130)
```

When we do this rescaling, the original *units of measurement* for the data cancel out and the new units are "SDs". This is why it is *standardized* and applicable across a range of problems. 


## A Mound-Shaped Example

Notice that the center of the data distribution is 0. Values *below* the mean have a negative *z*-score. Observations more than 2 or 3 SDs from the mean can be considered "in the tail".

```{r, echo = FALSE, fig.align="center", fig.cap="*standardized values on a bell-shaped distribution.*"}
knitr::include_graphics("../images/stdstatbellcurve.png", dpi = 120)
```

The farther from zero the standardized statistic is, the stronger the evidence against the null hypothesis. Like a *p*-value, we can directly compare standardized values across datasets. 


## Quantifying Strength of Evidence

In this context, the **<mark>*z*-score</mark>** measures how extreme the observed statistic is relative to the value hypothesized in $H_0$. The sign in $H_a$ will indicate whether we consider positive values (right tail), negative values (left tail), or both (two-tailed).

| Magnitude of *z*-score       | Strength of evidence provided by the *z*-score               |
|------------------------------|--------------------------------------------------------------|
| *z* between -1.5 and +1.5    | **NOT MUCH** evidence against the null hypothesis ($H_0$)    |
| *z* below -1.5 or above +1.5 | **MODERATE** evidence against the null hypothesis ($H_0$)    |
| *z* below -2.0 or above +2.0 | **STRONG** evidence against the null hypothesis ($H_0$)      |
| *z* below -3.0 or above +3.0 | **VERY STRONG** evidence against the null hypothesis ($H_0$) |


## General Rule for Statistical Significance

<p>We will declare the chance model ***implausible*** and reject $H_0$ if...</p>

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/freddiemercuryzscore.jpg", dpi = 100)
```

<p style="text-align:center; font-size: 12px;">With all due respect to the [late, great Freddie Mercury](https://youtu.be/FP808MiJUcM).</p>


## Other Types of Standardized Scores

There are other versions of standardized scores with non-zero means. For example, IQ test scores are often adjusted to have a mean of 100 and SD of 15, similar to how 0 °C can be re-scaled to 32 °F. Below is an example from the [Cora Lee Institute](https://coraleeinstitute.org/understanding-standardized-test-scores/).

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/testscores.jpg", dpi = 140)
```


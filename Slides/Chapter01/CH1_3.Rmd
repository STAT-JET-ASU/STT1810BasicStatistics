---
title: "Section 1.3 Strength of Evidence (an Alternative)"
subtitle: "*Introduction to Statistical Investigations, 2^nd^ Edition*"
author: "Jill E. Thomley | **STT 1810 BASIC STATISTICS** | Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: ../images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```


## Before We Begin…

These slides were created to accompany the text [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html) --- Section 1.3 Alternative Measure of Strength of Evidence. 

*This content does not replace reading the relevant textbook section.* It is for class presentation, review, and reference.

See [AsULearn](https://asulearn.appstate.edu/) for additional readings, videos, and assignments.


## Recall: Spiral Approach & Four Pillars

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* **We will address strength of evidence (*significance*) in Chapter 1.**

* We will discuss breadth of results (*generalization*) in Chapter 2.

* We will learn about effect size of results (*estimation*) in Chapter 3.

* Chapter 4 will introduce the idea of *causation*, the last of the four pillars. 

:::

::::


## Learning Goals for Chapter 1

* Use the chance model to determine whether an observed statistic is unlikely to occur. [Section 1.1]
* Calculate and interpret a *p*-value, and state the strength of evidence it provides against the null hypothesis. [Section 1.2]
* Calculate a standardized statistic for a single proportion and evaluate the strength of evidence it provides against a null hypothesis. [Section 1.3]
* Describe how the distance of the observed statistic from the parameter value specified by the null hypothesis, sample size, and one- vs. two-sided tests affect the strength of evidence against the null hypothesis. [Section 1.4]

<hr>

We will not cover Section 1.5, which introduces a theory-based method of inference for a single proportion.


## Learning Goals for Section 1.3

* Find a standardized statistic from the observed proportion of “successes” in the data, the hypothesized mean of the null distribution, and the standard deviation (SD) of the null distribution as produced by the ISI [One Proportion](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) applet.
* Interpret a standardized statistic.
* State a conclusion about the alternative hypothesis (and null hypothesis Ho) based on the magnitude of the standardized statistic.
* Recognize that standardizing the statistic is an alternative measure of strength of evidence.


## Recall from Section 1.2

**test of significance (or significance test):** the formal process we usually use for any assessment of strength of evidence

(1) Make a claim about the parameter of interest ($H_0$ and $H_a$) 
(2) Gather and explore data relevant to the claim
(3) Calculate an observed statistic from the data
(4) Simulate a null distribution (assuming that $H_0$ is true)
(5) Measure the strength of evidence that the observed statistic provides against Ho (using the null distribution as a "ruler")
(6) Draw a conclusion about the null hypothesis 

*Recall that steps 3, 4, and 5 are the components of the **3S process!***


## Section 1.3 New Vocabulary

**<mark>standardize / standardized statistic</mark> :** To standardize a statistic, compute the distance of the observed statistic from the mean of the null distribution (*corresponding with $H_0$*), then divide by the standard deviation (SD) of the null distribution.

$$\text{std. statistic} = \frac{\text{statistic} - \text{mean of null distribution}}{\text{SD of null distribution}}$$

<p>&nbsp;<p>

The standardized statistic tells us how many SDs above or below the hypothesized mean the observed statistic is.

<hr>

The standardized value is also often referred to as the **<mark>*z*-score</mark>**.

<hr>


## 

Mathematically, standardizing is similar to transforming °F to °C. It's a new numerical scale for expressing the quantity, but it does not change the *meaning* of the actual data values. 

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/temprescaling.png", dpi = 130)
```

When we do this rescaling, the original *units of measurement* for the data cancel out and the new units are "SDs". This is why it is *standardized* and applicable across a range of problems. 


## A Mound-Shaped Example

Notice that the center of the distribution is 0. Values *below* the mean have a negative $z$-score. Observations more than 2 or 3 SDs from the mean can be considered "in the tail".

```{r, echo = FALSE, fig.align="center", fig.cap="*standardized values on a bell-shaped distribution.*"}
knitr::include_graphics("../images/stdstatbellcurve.png", dpi = 120)
```

The farther from zero the standardized statistic is, the stronger the evidence against the null hypothesis. Like a *p*-value, we can directly compare standardized values across datasets. 


## Standardized Test Scores

There are other kinds of standardized scores with scaled means and SDs. For example, IQ test scores are often adjusted to have a mean of 100 and SD of 15, similar to how 0 °C can be re-scaled to 32 °F. This is an example from the [Cora Lee Institute](https://coraleeinstitute.org/understanding-standardized-test-scores/).

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/testscores.jpg", dpi = 130)
```


---
title: "Section 3.2<br> ± 2SD Approximate CIs"
subtitle: "*Introduction to Statistical Investigations, 2^nd^ Edition*"
author: "Jill E. Thomley | **STT 1810 BASIC STATISTICS** | Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: ../images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
library(tidyverse)
```

## Before We Begin…

These slides are meant to accompany the text [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html) --- Section 3.2 2SD and Theory Based Confidence Intervals for a Single Proportion. 

*This content does not replace reading the relevant textbook section.* It is for class presentation, review, and reference.

See [AsULearn](https://asulearn.appstate.edu/) for additional readings, videos, and assignments.


## Recall: Spiral Approach & Four Pillars

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* We addressed strength of evidence (*significance*) in Chapter 1. ✔ ***Good job!***

* We addressed the breadth of results (*generalization*) in Chapter 2. ✔ ***Good job!***

* **We will discuss the effect size of results (*estimation*) in Chapter 3.**

* Chapter 4 will introduce the idea of *causation*, the last of the four pillars. 

:::

::::


## Learning Goals for Chapter 3

Chapter 3 focuses on ***estimation***, which is one of the four pillars of inference introduced in Section P.1. Often, we use estimation to indicate how large an effect is, not as a single number, but as an ***interval*** of statistically likely or plausible values.

<hr>

* Construct and interpret a confidence interval for a single population proportion using the range of plausible values technique. [Section 3.1]
* Construct and interpret a confidence interval for a single population proportion using the 2SD method. [Section 3.2]
* Identify how factors (confidence level, sample size, SD) affect the width of the confidence interval. [Section 3.4]

We will not cover Section 3.3, theoretical estimation for a mean.


## Learning Goals for Section 3.2

In Section 3.1 you learned about estimation using intervals of plausible values. In Section 3.2, you will explore how to create confidence intervals using standardization --- in particular, the “two standard deviation method” (or the "2SD method") for an approximate 95% confidence interval.

<hr>

* Compute a confidence interval for a proportion written in terms of its endpoints vs. a confidence interval written in terms of center plus or minus a margin of error.
* Approximate a 95% confidence interval (CI) for a proportion by using the 2SD method.

*Note: We will not be doing the theory-based confidence intervals introduced in this section. Focus on the 2SD method.*


## Section 3.2 New Vocabulary

Recall that you learned about $SD(\hat{p})$, the standard deviation of $\hat{p}$, and the Central Limit Theorem in Section 2.1 

**<mark>2SD method (for CI)<mark> :** if a sampling distribution is approximately normal, we can approximate a 95% confidence interval by taking the statistic and the SD of the statistic and extending the interval 2 SDs in each direction from the statistic

$$\text{approximate 95% CI for } \hat{p} = \hat{p} \pm 2 \times SD(\hat{p})$$

**<mark>margin of error<mark> :** the half-width of a confidence interval (for the 2SD method, this is the ± 2SD value)

**<mark>standard error / SE<mark> :** an estimate of the standard deviation of a statistic that is based on observed data


## Empirical Rule: Why 2SD Works

For a bell-shaped (normal) curve, about 95% of the distribution will be within ±2SD of the mean---the basis of the 2SD method.

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/empiricalrule.png", dpi = 110)
```

We could also create 68% and 99.7% CIs using ±1SD and ±3SD.


## The 2 Standard Deviation (SD) Method

Calculate the observed sample proportion $\hat{p}$.

Simulate the sampling distribution of  $\hat{p}$ using the same sample size $n$ as the observed sample and $\pi = 0.5$.

Calculate the standard deviation of the simulated distribution to get an estimate for the value of $SD(\hat{p})$.

Plug the values into the equation below to get a 95% confidence interval for $\pi$, based on the sample data.

$$\hat{p} \pm 2 \times SD(\hat{p})$$

<hr>

Recall that we use $\pi = 0.5$ because $SD(\hat{p})$ is the biggest then.

## Example: Largest SD for $n = 100$?

| $n$   |  $\pi$ |     $SD(\hat{p})$     |
|:-----:|:------:|:---------------------:|
|  100  |  0.10  |        0.0300         |
|  100  |  0.25  |        0.0433         |
|  100  |  0.40  |        0.0490         |
|  100  |  0.50  |**<mark>0.0500</mark>**|
|  100  |  0.60  |        0.0490         |
|  100  |  0.75  |        0.0433         |
|  100  |  0.90  |        0.0300         |


## Recall Learning in Section 2.1

```{r echo = FALSE, fig.align = "center"}
df2 <- tibble(pi = c(0.01, seq(0.0, 1, 0.10), 0.99), SD = sqrt((pi * (1 - pi)) / 100))
ggplot(df2, aes(x = pi, y = SD)) +
  geom_line() +
  geom_point(size = 2) +
  geom_hline(yintercept = 0) +
  geom_vline(xintercept = -0.05) +
  scale_x_continuous(limits = c(-0.05, 1.05), breaks = seq(0, 1, 0.1), expand = c(0, 0)) +
  scale_y_continuous(limits = c(0, 0.06), expand = c(0, 0)) +
  theme_minimal() +
  labs(
    title = "Relationship Between π and SD(p̂) for n = 100",
    x = "value of π",
    y = "Variability of the Sampling Distribution --- SD(p̂)"
  ) +
  annotate(
    "label",
    x = 0.5,
    y = 0.055,
    label = "for any given sample size (n), the largest SD is always when π = 0.5",
    fill = "peachpuff"
  ) +
  annotate(
    "point",
    x = 0.5,
    y = 0.05,
    color = "darkorange",
    size = 5
  ) +
  annotate(
    "label",
    x = 0.175,
    y = 0.005,
    label = "SD = 0 when π = 0",
    fill = "lightblue"
  ) +
  annotate(
    "label",
    x = 0.825,
    y = 0.005,
    label = "SD = 0 when π = 1",
    fill = "lightblue"
  ) +
  annotate(
    "point",
    x = c(0, 1),
    y = 0,
    color = "blue",
    size = 5
  )
```

Using the largest SD helps us not to overstate our confidence.


## Flashback: Harley the Wonder Doggo

Use the sample proportion $0.90$ and the simulated SD = $0.158$ (refer to Exploration 1.1 if needed) in the calculation.

$$\hat{p} \pm 2 \times SD(\hat{p}) = 0.90 \pm 2 \times 0.158 = 0.90 \pm 0.316$$

We are 95% confident that Harley's true chance of choosing the correct cup is is between $0.90 \pm 0.316$. The margin of error on the estimate is $0.316$ or $31.6\%$.

We can also write the CI as $(0.584, 1.216)$. We know $\pi$ cannot be &geq; 1, so the interval is effectively $(0.584, 0.999)$

Note that all plausible values included in the interval are greater than 50%. Based on this, we can be confident in this context that the true proportion is greater than random chance.


## Simulating the SD for Harley's Trials

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/harleyCIsimulationSD.png", dpi = 120)
```

<hr>

We always use $\pi = 0.5$ to estimate SD in this CI method. Notice how larger sample sizes yield smaller SDs in the next examples.


## Flashback: Bottled vs. Tap Water

The sample proportion of people who preferred **tap water** was $\hat{p} = 0.1111$. Use the sample size $n = 27$ and $\pi = 0.5$ to find the simulated $SD(\hat{p}$, which should be about $0.096$.

$$\hat{p} \pm 2 \times SD(\hat{p}) = 0.111 \pm 2 \times 0.096 = 0.111 \pm 0.192$$

We are $95\%$ confident that the long-run probability a person would prefer tap water to bottled water when presented with the kind of choice offered in the experiment with four cups is between $-0.081$ and $0.303$, or roughly about $1\%$ to $30\%$.

Note that $\pi = 0.25$ is among the plausible values included in the interval. This is consistent with our failure to find statistical significance in Exploration 1.2. *Random choice is plausible.*


## Simulating the SD for Bottled vs. Tap

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/waterCIsimulationSD.png", dpi = 120)
```

<hr>

We always use $\pi = 0.5$ to estimate SD in this CI method, even though we DID NOT use $H_0: \pi = 0.5$ in our significance test.



## Flashback: Bob or Tim?

Combining two classes of previous STT 1810 students, 31 of 38 students $(\hat{p} = 0.816)$ assigned the name Tim to the left face. Using simulation, the estimated $SD(\hat{p}) = 0.081$.

$$\hat{p} \pm 2 \times SD(\hat{p}) = 0.816 \pm 2 \times 0.081 = 0.816 \pm 0.162$$

We are $95\%$ confident that the long-run proportion of students who would assign the name Tim to the left face when given the same choice we used is between $65.4\%$ and $97.8\%$.

All plausible values in the interval are greater than $50\%$. We can be confident that the true proportion $\pi$ is greater than random chance in this context, based on our experiment --- students do have a preference for saying Tim is on the left.


## Simulating the SD for "Bob or Tim?"

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/bobtimCIsimulationSD.png", dpi = 110)
```

<hr>

Remember, use $\pi = 0.5$ here regardless of the null hypothesis.

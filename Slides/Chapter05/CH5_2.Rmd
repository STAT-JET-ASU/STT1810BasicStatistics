---
title: "Section 5.2 Comparing<br>Two Proportions: Sims"
subtitle: "*Introduction to Statistical Investigations, 2^nd^ Edition*"
author: "Jill E. Thomley | **STT 1810 BASIC STATISTICS** | Appalachian State University"
date: "Last updated `r format(Sys.time(), '%A, %B %d, %Y @ %I:%M %p')`"
output: 
  ioslides_presentation:
    logo: ../images/logoASU.jpg
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  comment = NA
)
```


## Before We Begin…

These slides are meant to accompany [*Introduction to Statistical Investigations, 2nd Edition*](http://www.isi-stats.com/isi/index2nd.html) --- Section 5.2 Comparing Two Groups: Categorical Response.

*This content does not replace reading the relevant textbook section.* It is for class presentation, review, and reference.

See [AsULearn](https://asulearn.appstate.edu/) for supplemental readings, videos, assignments, and searchable Glossary of ISI Textbook Vocabulary.


## Recall: The Six-Step Spiral Process

:::::: {style="display: flex;"}

::: {}

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/sixstepsfourpillars.png", dpi = 100)
```

:::

::: {}

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

:::

::: {}

* In Chapters 1 through 4, our research questions usually involved a single proportion parameter $\pi$.

* In Chapter 5 we will look at comparing parameters for two groups ($\pi_1, \pi_2$).

* The investigative process is the same; the six-step "spiral" we introduced in Section P.1.

* Now Ho will be written as a *difference* in parameters. 

:::

::::


## Learning Goals for Chapter 5

Chapter 5 extends what we learned about statistical significance in previous chapters to compare two groups with parameters $\pi_1$ and $\pi_2$. In this case, rather than testing a null hypothesis about whether $\pi$ is equal to some value, we will typically have a null of $H_0: \pi_1 = \pi_2$ or $H_0: \pi_1 - \pi_2 = 0$ &rarr; there is *no difference*. 

We can also estimate the size of difference between $\pi_1$ and $\pi_2$.

<hr>

In Chapter 5 (*not including Section 5.3*), you will learn to: 

* Compare two sample proportions numerically and graphically. [Section 5.1]
* Carry out a simulation-based analysis to investigate the difference between two population proportions. [Section 5.2]


## Learning Goals for Section 5.2

* State Ho and Ha in terms of “no association” versus “there is an association” as well as in terms of comparing probabilities of success for two categories of explanatory variable ($\pi_1$ and $\pi_2$) when exploring the relationship between two categorical variables.

* Implement the 3S strategy: find a statistic, simulate the null distribution, and compute the strength of evidence...

* Describe how to use cards to simulate what outcomes (in terms of difference in conditional proportions and/or relative risk) are to be expected in repeated random assignments, if there is no association between the two variables.

* Use the [ISI Two Proportions applet](http://www.isi-stats.com/isi2nd/ISIapplets2021.html) to conduct a simulation of the null hypothesis and be able to read the applet output.


##

* Find and interpret the standardized statistic and the *p*-value for a test of two proportions.

* Use the 2SD method to find a 95% confidence interval for the difference in long-run proportion of success for two “treatment” groups, and interpret the interval in the context of the study.

* Interpret what it means for the 95% confidence interval for difference in proportions to contain zero.

* State a complete conclusion about the null and alternative hypotheses based on the *p*-value / standardized statistic and the study design, including statistical significance, estimation (confidence interval), generalizability, and causation.


## Section 5.2 New Vocabulary

**standard error:** an estimate for the standard deviation of the null distribution of a statistic

You may also want to review and solidify all of the vocabulary introduced in Section 5.1, especially the supplemental content like percent increased risk and odds ratio.

<hr>

The term *standard error* is not completely new. We mentioned it in Section 2.1, when we explored the sampling distribution for a single proportion. 

We also encountered it in Section 3.2 when we introduced 2SD confidence intervals.

We will revisit both of those ideas in Section 5.2!


## The Hypotheses: Version 1

Suppose we have two variables, ***explanatory*** and ***response***. We can use the association language learned in Chapter 4 to write hypotheses in the following form.

* $H_0:$ There ***is no association*** between the explanatory variable and the response variable.

In other words, the categories of the explanatory variable have no impact on the response. The conditional proportions for the two groups are the same---*group membership does not matter*.

* $H_a:$ There ***is an association*** between the explanatory variable and the response variable.

Conditional proportions in the explanatory groups are different. Group membership gives you information about the response.


## The Hypotheses: Version 2

We can also write our hypotheses using parameters, like we did in Chapter 1 and Chapter 3. We define ***two*** parameters, one for each of the two groups of the explanatory variable.

$\pi_1$ = conditional proportion of successes (***response variable***) in Group 1 of the ***explanatory variable***

$\pi_2$ = conditional proportion of successes (***response variable***) in Group 2 of the ***explanatory variable***

* $H_0:$ The conditional proportion of successes in Group 1 is the same as in Group 2.
* $H_a:$ The conditional proportion of successes in Group 1 is (*less than*, *different than*, or *greater than*) in Group 2.


## Stating the Hypotheses With Symbols

Once again, we can convert the words to symbols.

$$H_0: \pi_1 = \pi_2$$

$$H_a: \pi_1 < \pi_2 \text{ or } H_a: \pi_1 \neq \pi_2 \text{ or } H_a: \pi_1 > \pi_2$$

We are really interested in the *difference* between the groups, so the hypotheses can be expressed as a mathematical difference. Subtract $\pi_2$ from both sides and we get, for example...

$$H_0: \pi_1 - \pi_2 = 0$$

$$H_a: \pi_1 -\pi_2 < 0 \text{ or } H_a: \pi_1 - \pi_2 \neq 0 \text{ or } H_a: \pi_1 -\pi_2 > 0$$

The sample difference ($\hat{p}_1 - \hat{p}_2$) will be the statistic for the test.


## Assess Statistical Significance #1

As we did with one-proportion tests, we will find a *p*-value using the test statistic and a simulated null distribution.

<hr>

Recall our guidelines for *p*-values from Section 1.2.

| Magnitude               | Guideline for Inference                                        |
|-------------------------|----------------------------------------------------------------|
| *p*-value > 0.10        | not much evidence against the null hypothesis; Ho is plausible |
| 0.05 < *p*-value ≤ 0.10 | moderate evidence against the null hypothesis                  |
| 0.01 < *p*-value ≤ 0.05 | strong evidence against the null hypothesis                    |
| *p*-value ≤ 0.01        | very strong evidence against the null hypothesis               |


## The Two-Proportion Applet

Recall the oral cancer example from Section 5.1. This is a test of significance for that data. The [Two Proportions applet](https://www.isi-stats.com/isi2nd/ISIapplets2021.html) generates the null distribution by randomly *re-shuffling* the data.

```{r, echo = FALSE, fig.align="center"}
knitr::include_graphics("../images/twopropapplet2.png", dpi = 135)
```


## Standardized Score

The general form for a standardized ($z$) score, which we first saw back in Chapter 1, is as follows.

$$z\text{-score} = \frac{\text{statistic} - \text{mean of the null distribution}}{\text{SD of the null distribution}}$$

When $H_0: \pi_1 - \pi_2 = 0$, the mean of the null distribution will be zero. This simplifies it a bit.

$$z\text{-score} = \frac{\hat{p}_1 - \hat{p}_2}{SD(\hat{p}_1 - \hat{p}_2)}$$

<hr>

Recall: $SD(\hat{p}_1 - \hat{p}_2)$ is notation for "SD of the null distribution of $(\hat{p}_1 - \hat{p}_2)$," not multiplication. We estimate SD from the sim.


## Assess Statistical Significance #2

Like we did with one-proportion tests, we can use the $z$-score to assess statistical significance.

<hr>

Recall our guidelines for $z$-scores from Section 1.3.

| Magnitude                | Guideline for Inference                       |
|--------------------------|-----------------------------------------------|
| between -1.5 and +1.5    | not much evidence against Ho; Ho is plausible |
| below -1.5 or above +1.5 | moderate evidence against Ho                  |
| below -2.0 or above +2.0 | strong evidence against Ho                    |
| below -3.0 or above +3.0 | very strong evidence against Ho               |


## 2SD Confidence Interval

Here we will estimate the magnitude of the difference between two parameters with a confidence interval, similar to the way we estimated one parameter. Recall what we learned in Section 3.2 about 2SD confidence intervals.

$$\text{approximate 95% CI} = \hat{p} \pm 2 \times SD(\hat{p})$$

Now our statistic is $(\hat{p}_1 - \hat{p}_2)$ rather than $\hat{p}$, so we substitute it for $\hat{p}$ in the formula above.

$$\text{95% CI} = (\hat{p}_1 - \hat{p}_2) \pm 2 \times SD(\hat{p}_1 - \hat{p}_2)$$

<hr>

Important: *Do not* multiply SD by $(\hat{p}_1 - \hat{p}_2)$ in the 2SD interval. Again, we estimate the SD value from the simulation results.

